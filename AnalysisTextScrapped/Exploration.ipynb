{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/krutheekarajkumar/PycharmProjects/Proj1venv/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "# checking to make sure kernal is within virtual environment \n",
    "import sys\n",
    "import site\n",
    "print(site.getsitepackages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import csv\n",
    "\n",
    "#Natural Language Processing Packages\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of commonly occuring stop words from http://www.nltk.org/nltk_data/\n",
    "stopwords = open(\"english\", \"r\")\n",
    "stopwords = [word for word in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works!\n",
    "def extract_job_title_from_result(soup):\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# companies work, and the list of IDs also work\n",
    "def extract_company_from_result(soup):\n",
    "    companies = []\n",
    "    recJobLoc = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        jobrecloc = div.find_all(name=\"div\", attrs = {\"class\":\"recJobLoc\"})\n",
    "        for jobid in jobrecloc:\n",
    "            recJobLoc.append(jobid.get(\"id\").replace(\"recJobLoc_\", \"\"))\n",
    "        company = div.find_all(name=\"span\", attrs = {\"class\":\"company\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs = {\"class\":\"result - link - source\"})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return (companies, recJobLoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DECOMISSIONED_extract_location_from_result(soup):\n",
    "    locations = []\n",
    "    spans = soup.findAll(\"span\", attrs={\"class\": \"location\"})\n",
    "    for span in spans:\n",
    "        locations.append(span.text)\n",
    "    return(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isQualification(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+') \n",
    "    porter = PorterStemmer()\n",
    "    keywords = ['experi','requir','qualif','skill', 'educ']\n",
    "    # Cleaning text\n",
    "    clean_text = []\n",
    "    new_text = re.sub('\\n', '', text)\n",
    "    new_text = re.sub('%', '', new_text)\n",
    "    new_text = re.sub('@', '', new_text)\n",
    "    new_text = re.sub(r'[0-9]', '', new_text)\n",
    "    new_text = new_text.lower()\n",
    "    new_text = tokenizer.tokenize(new_text)\n",
    "    #print(new_text)\n",
    "    for nt in new_text: \n",
    "        if nt in stopwords:\n",
    "            pass\n",
    "        else: \n",
    "            clean_text.append(nt)\n",
    "            #stemmedword.append(porter.stem(nt))\n",
    "            if porter.stem(nt) in keywords:\n",
    "                return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DECOMMISIONED_extract_salary_from_result(soup):\n",
    "    salaries = []\n",
    "    desiredQualifications = []\n",
    "    desiredQualificationsDescription = []\n",
    "    \n",
    "    for headers in soup.find_all(name='h1'):\n",
    "        if isQualification(headers.text):\n",
    "            desiredQualifications.append(headers.parent.next_sibling.text)\n",
    "    for headers in soup.find_all(name='h2'):\n",
    "        if isQualification(headers.text):\n",
    "            desiredQualifications.append(headers.parent.next_sibling.text)\n",
    "    for headers in soup.find_all(name='h3'):\n",
    "        if isQualification(headers.text):\n",
    "            desiredQualifications.append(headers.parent.next_sibling.text)\n",
    "    \n",
    "    \"\"\"for div in soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
    "        for item in div.find_all('b'):\n",
    "            if isQualification(item.text):\n",
    "                for tag in item.next_elements:\n",
    "                    print(\"NAME:\", tag.name)\n",
    "                    print(\"TAG: \", tag)\"\"\"\n",
    "                    \n",
    "    for div in soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
    "        for tag in div.next_elements:\n",
    "            if (tag.name == 'b') and isQualification(tag.text) == True:\n",
    "                for t in tag.next_elements:\n",
    "                    if  t.name == 'script' or t.name == 'span':\n",
    "                        break \n",
    "                    else:\n",
    "                        try:\n",
    "                            desiredQualificationsDescription.append(t.text)\n",
    "                        except: \n",
    "                            pass\n",
    "            else: \n",
    "                pass\n",
    "        \n",
    "   \n",
    "                \n",
    "                #if isQualification(item.text) == True:\n",
    "                #    print(\"HERE: \", item.text)\n",
    "                #    print(\"***********\")\n",
    "                    #for tag in item.next_elements:\n",
    "                    #    print(\"NAME:\", tag.name)\n",
    "                    #    print(\"TAG: \", tag)\n",
    "    \n",
    "\n",
    "                #print([tag.name if tag.name else tag for tag in item.parent.next_elements])\n",
    "                #desiredQualificationsDescription.append(item.parent.next_sibling.text)\n",
    "            #salaries.append(item.text)\n",
    "        \"\"\"try:\n",
    "        \n",
    "            salaries.append(div.find(\"nobr\").text)\n",
    "        except:\n",
    "            try:\n",
    "                div_two = div.find(name=\"div\", attrs={\"class\":\"salaryText\"})\n",
    "                div_three = div_two.find(\"div\")\n",
    "                salaries.append(div_three.text.strip())\n",
    "            except:\n",
    "                salaries.append(\"Nothing_found\")\n",
    "                 if len(desiredQualificationsDescription) == 0 or desiredQualificationsDescription[0] == \"\" : \n",
    "        for div in soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
    "            for i in div.find_all('div', string=re.compile(\"requir\")):\n",
    "                    print(\"****\")\n",
    "                    print(i)\"\"\"\n",
    "    desiredQualifications.extend(desiredQualificationsDescription)\n",
    "    if len(desiredQualifications) >= len(desiredQualificationsDescription):\n",
    "        return (desiredQualifications)\n",
    "    else:\n",
    "        return(desiredQualificationsDescription)\n",
    "    print(desiredQualifications)\n",
    "    #return(desiredQualifications)#, salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_requirements_from_result(soup):\n",
    "    salaries = []\n",
    "    desiredQualifications = []\n",
    "    desiredQualificationsDescription = []\n",
    "    desiredQualificationslists = []\n",
    "    \n",
    "    if len(desiredQualifications) == 0:\n",
    "        for headers in soup.find_all(name='h1'):\n",
    "            if isQualification(headers.text):\n",
    "                desiredQualifications.append(headers.parent.next_sibling.text)\n",
    "    elif len(desiredQualifications) == 0:           \n",
    "        for headers in soup.find_all(name='h2'):\n",
    "            if isQualification(headers.text):\n",
    "                desiredQualifications.append(headers.parent.next_sibling.text)\n",
    "    else:\n",
    "        for headers in soup.find_all(name='h3'):\n",
    "            if isQualification(headers.text):\n",
    "                desiredQualifications.append(headers.parent.next_sibling.text)\n",
    "\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
    "        for item in div.find_all('b'):\n",
    "            if isQualification(item.text):\n",
    "                for tag in item.parent.next_siblings:\n",
    "                    try:\n",
    "                        desiredQualificationsDescription.append(tag.text)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "    if len(desiredQualifications) < 50 and len(desiredQualificationsDescription)< 50:\n",
    "        for div in soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
    "            for item in div.find_all(\"li\"):\n",
    "                if isQualification(item.text):\n",
    "                    desiredQualificationslists.append(item.text)\n",
    "        return(desiredQualificationslists)\n",
    "    \n",
    "    else:\n",
    "        desiredQualifications.extend(desiredQualificationsDescription)\n",
    "        if len(desiredQualifications) >= len(desiredQualificationsDescription):\n",
    "            return (desiredQualifications)\n",
    "        else:\n",
    "            return(desiredQualificationsDescription)\n",
    "        print(desiredQualifications)\n",
    "    #return(desiredQualifications)#, salaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary_from_result(soup):\n",
    "    salary = \"None found\"\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"id\":\"jobDescriptionText\"}):\n",
    "        for item in div.find_all(\"p\"):\n",
    "            if re.search('\\$\\d+', item.text):\n",
    "                salary = item.text\n",
    "    \n",
    "    if re.search('\\$\\d+', salary) == False:\n",
    "        for item in div.find_all(\"b\"):\n",
    "            if re.search('\\$\\d+', item.text):\n",
    "                salary = item.text\n",
    "                \n",
    "    if re.search('\\$\\d+', salary) == False:\n",
    "        for item in div.find_all(\"span\"):\n",
    "            if re.search('\\$\\d+', item.text):\n",
    "                salary = item.text\n",
    "    \n",
    "    if re.search('\\$\\d+', salary) == False:\n",
    "        for item in div.find_all(\"il\"):\n",
    "            if re.search('\\$\\d+', item.text):\n",
    "                salary = item.text\n",
    "     \n",
    "    return salary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_locations_from_result(soup):\n",
    "    div = soup.find(name=\"div\", attrs={\"class\":\"jobsearch-InlineCompanyRating\"})\n",
    "    return (div.text)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Larson Design Group16 reviews-Beaver, PA 15009'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_job_locations_from_result(soup1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titlesOfInterest = []\n",
    "URL = \"https://www.indeed.com/jobs?q=data+engineer+%2420%2C000&l=Toronto&start=10\"\n",
    "\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/viewjob?cmp=LANXESS&jk=d1278daae9bfc93d\n",
      "LANXESS294 reviews-Pittsburgh, PA 15275\n",
      "https://www.indeed.com/viewjob?cmp=Kinetic%20Personnel%20Group%20Inc.&jk=f1de9c05321e8f24\n",
      "Kinetic Personnel Group Inc.11 reviews-United States\n",
      "https://www.indeed.com/viewjob?cmp=Eaton&jk=6905fadd4e4f978c\n",
      "Eaton4,338 reviews-Township of Moon, PA\n",
      "https://www.indeed.com/viewjob?cmp=Fidelity%20National%20Financial&jk=af747db88947fba8\n",
      "Fidelity National Financial682 reviews-Township of Moon, PA\n",
      "https://www.indeed.com/viewjob?cmp=EY&jk=146a36cd2c632f99\n",
      "EY7,618 reviews-United States\n",
      "https://www.indeed.com/viewjob?cmp=CleanAir%20Engineering,%20Inc.&jk=8997fef184366b2a\n",
      "CleanAir Engineering, Inc.-Pittsburgh, PA 15275\n",
      "https://www.indeed.com/viewjob?cmp=ITI%20Data&jk=4995af38496c8840\n",
      "ITI Data-United States\n",
      "https://www.indeed.com/viewjob?cmp=Mitigation%20Resources%20of%20North%20America&jk=c97056b340f99346\n",
      "Mitigation Resources of North America-United States\n",
      "https://www.indeed.com/viewjob?cmp=PrologMobile&jk=66fa324e50be9996\n",
      "PrologMobile-United States\n",
      "https://www.indeed.com/viewjob?cmp=International%20Litigation%20Services&jk=8ca7a368a9683676\n",
      "International Litigation Services-United States\n",
      "https://www.indeed.com/viewjob?cmp=Ongoing%20Operations,%20LLC&jk=61555ad12147b139\n",
      "Ongoing Operations, LLC3 reviews-United States\n",
      "https://www.indeed.com/viewjob?cmp=Visionnet&jk=355ccd7785dcb92e\n",
      "Visionnet7 reviews-Coraopolis, PA\n",
      "https://www.indeed.com/viewjob?cmp=ITI%20Data&jk=b3f478406e7a4a20\n",
      "ITI Data-United States\n",
      "https://www.indeed.com/viewjob?cmp=ASML&jk=6477da05db1f64db\n",
      "ASML278 reviews-Ohio\n",
      "https://www.indeed.com/viewjob?cmp=Larson%20Design%20Group&jk=9a5b8ad494525fb7\n",
      "Larson Design Group16 reviews-Beaver, PA 15009\n"
     ]
    }
   ],
   "source": [
    "#print(extract_job_title_from_result(soup))\n",
    "#print(extract_company_from_result(soup))\n",
    "#print(extract_location_from_result(soup))\n",
    "companyNames, indeedIdentification = extract_company_from_result(soup)\n",
    "qualifications = []\n",
    "for i in range(len(companyNames)):\n",
    "    cmpName = companyNames[i].replace(\" \", \"%20\")\n",
    "    cmpName = cmpName.replace(\"'\", \"%27\")\n",
    "    url1 = (f'https://www.indeed.com/viewjob?cmp={cmpName}&jk={indeedIdentification[i]}')\n",
    "    #url1 = 'https://www.indeed.com/viewjob?cmp=Monaloh%20Basin%20Engineers&jk=37f74a32956e413f'\n",
    "    print(url1)\n",
    "    page = requests.get(url1)\n",
    "    soup1 = BeautifulSoup(page.text, \"html.parser\")\n",
    "    try:\n",
    "        qualifications.append(extract_job_requirements_from_result(soup1))\n",
    "        print(extract_job_locations_from_result(soup1))\n",
    "        #print(extract_salary_from_result(soup1))\n",
    "    except:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Excellent analytical skills in the analysis of technical problems\\n',\n",
       " 'Excellent communication skills in contact with carriers, colleagues and customers in the trouble shooting process as well as the willingness to work in teams\\n',\n",
       " 'Direct the Process and Logistic Team in coordinating and performing tasks required for successful completion of projects, complex workflows, and troubles.\\n',\n",
       " 'Performing disaster recovery operations and data backups when required.\\n',\n",
       " 'Replacing faulty network hardware components when required.\\n',\n",
       " '2+ years of experience as a Network Engineer and 2 years with Switching.\\n',\n",
       " 'Experience with enterprise-level network design, engineering, and administration.\\n',\n",
       " 'Experience with common networking devices such as firewalls, switches, and fabric interconnects. Commonly used brands include VeloCloud, Arista, Cisco, Meraki, Aruba, Juniper and Palo Alto.\\n',\n",
       " 'Experience interfacing with customer POCs to evaluate networking needs or requirements and explain technical terms to non-technical users or stakeholders.\\n',\n",
       " 'Good analytical and problem-solving skills.\\n',\n",
       " 'Network security experience.\\n',\n",
       " 'LAN and WAN experience\\n',\n",
       " 'Comparable IT industry experience will be considered in lieu of a degree and certifications\\n',\n",
       " 'Experience with Meraki, Palo Alto, Aruba ClearPass, InfoBlox.\\n',\n",
       " 'Experience with VeloCloud Routers, Aruba Switches, Juniper Switches, Cisco Switches.\\n',\n",
       " \"Experience with Aruba AP's and Wireless Controllers, Meraki Wireless\\n\",\n",
       " 'Experience with Solarwinds, and/or other SNMP monitoring platforms.\\n']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qualifications[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataIntakeClean(text):\n",
    "    singleEntry = \"\"\n",
    "    for t in text:\n",
    "        t = t.replace(\"'\",\"\")\n",
    "        t = t.replace(\"\\n\",\"\")\n",
    "        singleEntry+=t\n",
    "    return (singleEntry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excellent analytical skills in the analysis of technical problemsExcellent communication skills in contact with carriers, colleagues and customers in the trouble shooting process as well as the willingness to work in teamsDirect the Process and Logistic Team in coordinating and performing tasks required for successful completion of projects, complex workflows, and troubles.Performing disaster recovery operations and data backups when required.Replacing faulty network hardware components when required.2+ years of experience as a Network Engineer and 2 years with Switching.Experience with enterprise-level network design, engineering, and administration.Experience with common networking devices such as firewalls, switches, and fabric interconnects. Commonly used brands include VeloCloud, Arista, Cisco, Meraki, Aruba, Juniper and Palo Alto.Experience interfacing with customer POCs to evaluate networking needs or requirements and explain technical terms to non-technical users or stakeholders.Good analytical and problem-solving skills.Network security experience.LAN and WAN experienceComparable IT industry experience will be considered in lieu of a degree and certificationsExperience with Meraki, Palo Alto, Aruba ClearPass, InfoBlox.Experience with VeloCloud Routers, Aruba Switches, Juniper Switches, Cisco Switches.Experience with Aruba APs and Wireless Controllers, Meraki WirelessExperience with Solarwinds, and/or other SNMP monitoring platforms.'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataIntakeClean(qualifications[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with open(\\'qualification.csv\\', \\'w\\', newline=\\'\\') as file:\\n    writer = csv.writer(file)\\n    writer.writerow([\"qualifications\"])\\n    for t in titlesOfInterest:\\n        writer.writerow([t])'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do not rewrite the .csv file \n",
    "\"\"\"with open('qualification.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"qualifications\"])\n",
    "    for t in titlesOfInterest:\n",
    "        writer.writerow([t])\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding to postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proj1venv",
   "language": "python",
   "name": "proj1venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
